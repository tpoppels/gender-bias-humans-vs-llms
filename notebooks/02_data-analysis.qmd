---
title: "Data Analysis: Visualizations and Hypothesis Tests"
author: "Till Poppels"
format: 
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    number-sections: true
    fig-format: "svg"
    fig-dpi: 300
execute:
  echo: true
  warning: false
  message: false
  error: true
  cache: false
---

```{r setup}
#| label: setup
#| include: false

library(tidyverse)
library(here)
library(ggplot2)
library(brms)
```

# Overview

In this notebook, we will analyze the data from the behavioral experiment (Part 1). We will start by visualizing the response times (RTs) and perform the formal hypothesis tests using the `brms` package.

Here's how we'll proceed:
1. Load the data
2. Visualize RTs around the first pronoun, comparing pre- and post-election data collection rounds
3. Fit a `brms` model and define hypothesis tests


# Load data

```{r load-data}
#| label: load-data

clean_data <- read_rds(here("data", "processed", "clean-data.rds"))

```

# Visualize RTs around the first pronoun, comparing pre- and post-election data collection rounds

```{r replicate-rt-by-rel-word-no-plot}
#| label: replicate-rt-by-rel-word-no-plot
#| fig-width: 6
#| fig-height: 3
#| dev: "svg"
#| fig-path: "figures/"  # This will save to a figures directory

clean_data |>
  filter(word_no_relative_to_first_pronoun %in% c(-5:5)) |>
  mutate(data_round = factor(data_round, levels = c("pre-election", "post-election"))) |>
  group_by(participant_id, data_round) |>
  mutate(pronoun_condition = case_when(
    word[is_first_pronoun] %in% c("he", "him", "his") ~ "masculine",
    word[is_first_pronoun] %in% c("she", "her") ~ "feminine",
    word[is_first_pronoun] %in% c("they", "them", "their") ~ "singular they",
    TRUE ~ NA_character_
  )) |>
  group_by(pronoun_condition, word_no_relative_to_first_pronoun, data_round) |>
  summarize(mean_rt = mean(response_time),
            n = length(response_time),
            se = sd(response_time) / sqrt(n)) |>
  ggplot(aes(x = word_no_relative_to_first_pronoun, y = mean_rt, color = pronoun_condition)) +
  facet_wrap(~data_round, ncol = 1) +
  geom_errorbar(aes(ymin = mean_rt - se, ymax = mean_rt + se), width = 0.2, position = position_dodge(width = 0.2)) +
  geom_line(position = position_dodge(width = 0.2)) +
  geom_point(position = position_dodge(width = 0.2)) +
  scale_y_continuous(name = "Response Time (ms)") +
  scale_x_continuous(name = "Word number relative to first pronoun",
                     breaks = c(-5:5)) +
  scale_color_manual(name = "Pronoun type",
                     values = c("masculine" = "red",
                                "feminine" = "blue",
                                "singular they" = "grey")) +
  theme_classic() ->
  g

ggsave(here("figures", "rt-by-pronoun-type-and-position.svg"),
       plot = g,
       width = 6,
       height = 3)
```

Before running the formal hypothesis tests, we can already see visually that:
1. Pre-election: feminine pronouns were processed more slowly than masculine pronouns
2. Post-election: the slow-down disappeared

# Fit a `brms` model and define hypothesis tests

In order to verify the visual findings, we will fit a `brms` model and define hypothesis tests. Since each participant only contributed a single data point, we do not need by-participant random effects, but we will include random effects for sentences (there were 12 sentences in total).

First, let's segment the data and visualize it descriptively. The dependent variable (on the Y axis) is pronoun RT, and our predictors (population-evel model coefficients) are whether or not the pronoun in question is feminine ("she", "her") or not ("he", "him", "his", "they", "them", "their"), and whether the data was collected before or after the election. We code the predictors such that the baseline is masculine pronouns and pre-election data, so that our hypotheses are:

1. Significantly positive coefficient for `feminine_pronoun`
2. Significantly negative coefficient for the `feminine_pronoun:post_election` interaction

```{r fit-brms-model}
#| label: fit-brms-model

clean_data |>
  filter(is_first_pronoun) |>
  mutate(feminine_pronoun = as.numeric(word %in% c("she", "her")),
         post_election = as.numeric(data_round == "post-election")) |>
  group_by(target_sentence_frame) |>
  mutate(sentence_id = paste("Sentence ", cur_group_id())) |>
  ungroup() ->
  data_for_model

brm(response_time ~ feminine_pronoun * post_election + (feminine_pronoun * post_election | sentence_id),
    data = data_for_model,
    family = gaussian(),
      chains = 4,
      cores = 4,
      iter = 2000,
      warmup = 1000,
      seed = 123) ->
  m


```

Our hypotheses are twofold:
1. Significantly positive coefficient for `feminine_pronoun` => would indicate that feminine pronouns were processed more slowly prior to the election
2. Significantly negative coefficient for the `feminine_pronoun:post_election` interaction => would indicate that the slow-down was significantly mitigated after the election

```{r hypothesis-tests}
#| label: hypothesis-tests

hypothesis(m, c("feminine_pronoun > 0", "feminine_pronoun:post_election < 0"))

```

Virtually all posterior samples are consistent with the hypotheses, hence the posterior probability of the hypotheses (given model and data) is 1.